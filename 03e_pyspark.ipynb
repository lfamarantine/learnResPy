{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### About **Spark**\n",
    "\n",
    "Spark is a platform for cluster computing. Spark lets you spread data and computations over clusters with multiple nodes\n",
    "(think of each node as a separate computer). Splitting up your data makes it easier to work with very large datasets\n",
    "because each node only works with a small amount of data.\n",
    "\n",
    "As each node works on its own subset of the total data, it also carries out a part of the total calculations required,\n",
    "so that both data processing and computation are performed in parallel over the nodes in the cluster. It is a fact\n",
    "that parallel computation can make certain types of programming tasks much faster.\n",
    "\n",
    "When to use Spark? Answering questions like the following is helpful:\n",
    "\n",
    "- Is my data too big to work with on a single machine?\n",
    "- Can my calculations be easily parallelized?\n",
    "\n",
    "Spark's core data structure is the Resilient Distributed Dataset (RDD). RDDs are hard to work with and one usually uses\n",
    "Spark DataFrame abstraction built on top of RDDs. DataFrames are also more optimized for complicated operations than\n",
    "RDDs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Setup\n",
    "To run spark locally on a windows machine, make sure to download `hadoop` [here](https://github.com/cdarlint/winutils)\n",
    "and add the following to the environmental variables:\n",
    "> `HADOOP_HOME=<your local hadoop folder (eg. C:\\usr\\bin\\Hadoop\\hadoop-3.2.2\\bin)>\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Session Initiation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- capital: string (nullable = true)\n",
      " |-- area: double (nullable = true)\n",
      " |-- population: double (nullable = true)\n",
      "\n",
      "+------------+------------+---------+-----+----------+\n",
      "|country_code|     country|  capital| area|population|\n",
      "+------------+------------+---------+-----+----------+\n",
      "|          BR|      Brazil| Brasilia|8.516|     200.4|\n",
      "|          RU|      Russia|   Moscow| 17.1|     143.5|\n",
      "|          IN|       India|New Delhi|3.286|    1252.0|\n",
      "|          CH|       China|  Beijing|9.597|    1357.0|\n",
      "|          SA|South Africa| Pretoria|1.221|     52.98|\n",
      "+------------+------------+---------+-----+----------+\n",
      "\n",
      "+------------+------------+---------+-----+----------+\n",
      "|country_code|     country|  capital| area|population|\n",
      "+------------+------------+---------+-----+----------+\n",
      "|          BR|      Brazil| Brasilia|8.516|     200.4|\n",
      "|          RU|      Russia|   Moscow| 17.1|     143.5|\n",
      "|          IN|       India|New Delhi|3.286|    1252.0|\n",
      "|          CH|       China|  Beijing|9.597|    1357.0|\n",
      "|          SA|South Africa| Pretoria|1.221|     52.98|\n",
      "+------------+------------+---------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "\n",
    "# create new spark session if necessary\n",
    "spark = SparkSession.builder.\\\n",
    "    config(\"spark.driver.host\", \"127.0.0.1\").\\\n",
    "    config(\"spark.driver.extraJavaOptions\", \"-Dio.netty.tryReflectionSetAccessible=true\").\\\n",
    "    config(\"spark.executor.extraJavaOptions\", \"-Dio.netty.tryReflectionSetAccessible=true\").\\\n",
    "    config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\").\\\n",
    "    config(\"spark.sql.shuffle.partitions\", \"8\").\\\n",
    "    config(\"spark.driver.memory\", \"8g\").getOrCreate()\n",
    "# list tables in cluster\n",
    "spark.catalog.listTables()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Reading / Importing Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- capital: string (nullable = true)\n",
      " |-- area: double (nullable = true)\n",
      " |-- population: double (nullable = true)\n",
      "\n",
      "+------------+------------+---------+-----+----------+\n",
      "|country_code|     country|  capital| area|population|\n",
      "+------------+------------+---------+-----+----------+\n",
      "|          BR|      Brazil| Brasilia|8.516|     200.4|\n",
      "|          RU|      Russia|   Moscow| 17.1|     143.5|\n",
      "|          IN|       India|New Delhi|3.286|    1252.0|\n",
      "|          CH|       China|  Beijing|9.597|    1357.0|\n",
      "|          SA|South Africa| Pretoria|1.221|     52.98|\n",
      "+------------+------------+---------+-----+----------+\n",
      "\n",
      "+------------+------------+---------+-----+----------+\n",
      "|country_code|     country|  capital| area|population|\n",
      "+------------+------------+---------+-----+----------+\n",
      "|          BR|      Brazil| Brasilia|8.516|     200.4|\n",
      "|          RU|      Russia|   Moscow|17.10|     143.5|\n",
      "|          IN|       India|New Delhi|3.286|      1252|\n",
      "|          CH|       China|  Beijing|9.597|      1357|\n",
      "|          SA|South Africa| Pretoria|1.221|     52.98|\n",
      "+------------+------------+---------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. PySpark dataframe from pandas\n",
    "# note: follow this process to make sure pyspark runs locally: https://github.com/cdarlint/winutils\n",
    "dfp = pd.read_csv(\"data/brics.csv\", index_col=0).rename_axis(\"country_code\").reset_index()\n",
    "dfs = spark.createDataFrame(dfp)\n",
    "dfs.printSchema()\n",
    "dfs.show()\n",
    "\n",
    "# 2.\n",
    "dfs_ = spark.read.csv(\"data/brics.csv\", header=True)\n",
    "dfs_ = dfs_.withColumnRenamed(\"_c0\", \"country_code\")\n",
    "dfs_.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Running SQL queries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+---------+-----+----------+\n",
      "|country_code|     country|  capital| area|population|\n",
      "+------------+------------+---------+-----+----------+\n",
      "|          BR|      Brazil| Brasilia|8.516|     200.4|\n",
      "|          RU|      Russia|   Moscow| 17.1|     143.5|\n",
      "|          IN|       India|New Delhi|3.286|    1252.0|\n",
      "|          CH|       China|  Beijing|9.597|    1357.0|\n",
      "|          SA|South Africa| Pretoria|1.221|     52.98|\n",
      "+------------+------------+---------+-----+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "  country_code       country    capital    area  population\n0           BR        Brazil   Brasilia   8.516      200.40\n1           RU        Russia     Moscow  17.100      143.50\n2           IN         India  New Delhi   3.286     1252.00\n3           CH         China    Beijing   9.597     1357.00\n4           SA  South Africa   Pretoria   1.221       52.98",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country_code</th>\n      <th>country</th>\n      <th>capital</th>\n      <th>area</th>\n      <th>population</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BR</td>\n      <td>Brazil</td>\n      <td>Brasilia</td>\n      <td>8.516</td>\n      <td>200.40</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RU</td>\n      <td>Russia</td>\n      <td>Moscow</td>\n      <td>17.100</td>\n      <td>143.50</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>IN</td>\n      <td>India</td>\n      <td>New Delhi</td>\n      <td>3.286</td>\n      <td>1252.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CH</td>\n      <td>China</td>\n      <td>Beijing</td>\n      <td>9.597</td>\n      <td>1357.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SA</td>\n      <td>South Africa</td>\n      <td>Pretoria</td>\n      <td>1.221</td>\n      <td>52.98</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# register the DF as a SQL temporary view\n",
    "dfs.createOrReplaceTempView(\"population\")\n",
    "df_sql = spark.sql(\"SELECT * FROM population\")\n",
    "df_sql.show()\n",
    "\n",
    "# convert results to pandas DF\n",
    "df_sql.toPandas()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}